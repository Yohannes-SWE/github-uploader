# User Flow Testing Suite

## Overview

This comprehensive testing suite covers all possible user interactions with the RepoTorpedo application. It tests every user journey, from initial registration to complex multi-provider deployments, ensuring the application works correctly in all scenarios.

## ğŸš€ Quick Start

### 1. Setup Testing Environment

```bash
# Navigate to the tests directory
cd tests

# Run the setup script
python3 setup_tests.py

# Start the mock server
./start_mock_server.sh

# Run quick tests
./run_tests.sh
```

### 2. Run Different Test Types

```bash
# Quick tests (critical paths only)
./run_tests.sh --quick

# Full test suite (all tests)
./run_tests.sh --full

# With coverage analysis
./run_tests.sh --coverage

# Generate HTML report
./run_tests.sh --report

# Verbose output
./run_tests.sh --verbose
```

## ğŸ“‹ Test Categories

### 1. Authentication Flow Tests

Tests user registration, login, logout, and session management.

**Coverage:**

- âœ… User registration with valid/invalid data
- âœ… User login with correct/incorrect credentials
- âœ… Session management and persistence
- âœ… Logout functionality
- âœ… Password validation and confirmation

### 2. Provider Configuration Flow Tests

Tests hosting provider setup and management.

**Coverage:**

- âœ… Get list of supported providers
- âœ… Configure Render, Vercel, Netlify, Railway providers
- âœ… Test provider connections
- âœ… Remove provider configurations
- âœ… Handle invalid API keys and configuration errors

### 3. Deployment Flow Tests

Tests application deployment to various providers.

**Coverage:**

- âœ… Single provider deployments
- âœ… Multi-provider deployments
- âœ… Deployments with custom domains
- âœ… Different environment types (Node.js, Python, Static)
- âœ… Environment variables and build commands
- âœ… Error handling and validation

### 4. Deployment Status Flow Tests

Tests deployment monitoring and status tracking.

**Coverage:**

- âœ… Get deployment history
- âœ… Monitor deployment status
- âœ… Real-time status updates
- âœ… Handle non-existent deployments

### 5. Custom Domain Flow Tests

Tests custom domain management.

**Coverage:**

- âœ… Add custom domains to services
- âœ… Domain validation
- âœ… Error handling for invalid domains

### 6. Error Handling Flow Tests

Tests application error handling and edge cases.

**Coverage:**

- âœ… Unauthenticated access attempts
- âœ… Invalid JSON requests
- âœ… Missing required fields
- âœ… Input validation errors
- âœ… Network and server errors

### 7. Performance Flow Tests

Tests application performance under load.

**Coverage:**

- âœ… Concurrent deployments
- âœ… Large payload handling
- âœ… Memory usage under load
- âœ… Response time testing

### 8. Security Flow Tests

Tests application security measures.

**Coverage:**

- âœ… Session security
- âœ… Input sanitization
- âœ… SQL injection prevention
- âœ… XSS prevention
- âœ… Authentication bypass attempts

### 9. Integration Flow Tests

Tests complete end-to-end user journeys.

**Coverage:**

- âœ… Complete user registration â†’ deployment flow
- âœ… Multi-provider setup and deployment
- âœ… Error recovery scenarios
- âœ… Provider management workflows

## ğŸ› ï¸ Test Infrastructure

### Mock Server

The `mock_server.py` provides a realistic simulation of the application API without requiring external dependencies.

**Features:**

- âœ… Complete API endpoint simulation
- âœ… Realistic response patterns
- âœ… Error simulation capabilities
- âœ… Session management
- âœ… Data persistence during test runs

### Test Configuration

The `test_config.json` contains all test settings and data.

**Configuration:**

- Test environment settings
- Provider configurations
- Test user data
- Repository examples
- Deployment configurations

### Test Data

Sample applications for testing different deployment scenarios:

- **React App**: `test_repositories/simple-react-app/`
- **Node.js API**: `test_repositories/node-api/`
- **Python Flask App**: `test_repositories/python-flask-app/`

## ğŸ“Š Test Results

### HTML Reports

Generate detailed HTML reports with test results:

```bash
./run_tests.sh --report
```

The report includes:

- âœ… Test execution summary
- âœ… Pass/fail statistics
- âœ… Error details and stack traces
- âœ… Performance metrics
- âœ… Coverage information

### Coverage Reports

Generate code coverage reports:

```bash
./run_tests.sh --coverage
```

Coverage includes:

- âœ… Line coverage
- âœ… Branch coverage
- âœ… Function coverage
- âœ… HTML coverage report

### Console Output

Real-time test progress and results:

```
ğŸš€ Starting User Flow Tests
ğŸ“ Base URL: http://localhost:5000
â° Start Time: 2024-01-15T10:30:00

ğŸ“‹ AuthenticationFlowTests: âœ… PASS
ğŸ“‹ ProviderConfigurationFlowTests: âœ… PASS
ğŸ“‹ DeploymentFlowTests: âœ… PASS
ğŸ“‹ IntegrationFlowTests: âœ… PASS

ğŸ“Š Test Summary
===============
âœ… Tests PASSED
â° Duration: 45.2s
ğŸ“ˆ Coverage: 89.5%
```

## ğŸ”§ Advanced Usage

### Running Specific Test Categories

```bash
# Run only authentication tests
python3 -m pytest user_flows.py::AuthenticationFlowTests -v

# Run only deployment tests
python3 -m pytest user_flows.py::DeploymentFlowTests -v

# Run specific test method
python3 -m pytest user_flows.py::AuthenticationFlowTests::test_01_user_registration_flow -v
```

### Parallel Test Execution

```bash
# Run tests in parallel (experimental)
python3 run_tests.py --parallel
```

### Custom Test Configuration

Edit `test_config.json` to customize:

- Test environment settings
- Provider configurations
- Test data
- Timeout values

### Environment Variables

Set custom environment variables:

```bash
export TEST_BASE_URL="http://localhost:5000"
export TEST_VERBOSE="true"
export TEST_COVERAGE="true"
```

## ğŸ› Debugging Tests

### Verbose Output

Enable detailed logging:

```bash
./run_tests.sh --verbose
```

### Debug Mode

Run tests with debug information:

```bash
python3 run_tests.py --base-url http://localhost:5000 --verbose
```

### Mock Server Debug

Start mock server in debug mode:

```bash
python3 mock_server.py --debug
```

### Test Isolation

Each test runs in isolation with cleanup:

- âœ… Fresh user sessions
- âœ… Clean provider configurations
- âœ… Isolated deployment data
- âœ… Automatic cleanup after tests

## ğŸ“ˆ Continuous Integration

### GitHub Actions

Automated testing on every commit:

```yaml
name: User Flow Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Run tests
        run: |
          cd tests
          python setup_tests.py
          python mock_server.py &
          python run_tests.py --full --coverage
```

### Local CI

Run the same tests locally:

```bash
# Setup and run full test suite
python3 setup_tests.py
./start_mock_server.sh &
./run_tests.sh --full --coverage --report
```

## ğŸ“š Documentation

### Test Scenarios

Detailed documentation of all test scenarios:

- [Test Scenarios Documentation](test_scenarios.md)

### API Documentation

Mock server API endpoints:

- [Mock Server API](mock_server.py)

### User Journeys

Complete user journey maps:

- [User Journey Documentation](test_scenarios.md#user-journey-maps)

## ğŸš¨ Troubleshooting

### Common Issues

**Server not responding:**

```bash
# Check if mock server is running
curl http://localhost:5000/health

# Restart mock server
./start_mock_server.sh
```

**Test failures:**

```bash
# Check test logs
./run_tests.sh --verbose

# Validate test setup
python3 setup_tests.py --validate-only
```

**Dependency issues:**

```bash
# Reinstall dependencies
python3 setup_tests.py --no-deps
```

### Performance Issues

**Slow test execution:**

- Use `--quick` flag for faster tests
- Run tests in parallel with `--parallel`
- Optimize test data size

**Memory issues:**

- Reduce concurrent test count
- Clean up test data regularly
- Monitor system resources

## ğŸ¤ Contributing

### Adding New Tests

1. **Create test class:**

```python
class NewFeatureTests(UserFlowTestBase):
    def test_new_feature(self):
        # Test implementation
        pass
```

2. **Add to test runner:**

```python
# In run_tests.py
test_classes.append(NewFeatureTests)
```

3. **Update documentation:**

- Add to test scenarios
- Update user journey maps
- Document new test data requirements

### Test Best Practices

- âœ… Use descriptive test names
- âœ… Test both success and failure scenarios
- âœ… Clean up after each test
- âœ… Use realistic test data
- âœ… Document test assumptions
- âœ… Keep tests independent

### Code Style

- Follow PEP 8 guidelines
- Use type hints
- Add docstrings to test methods
- Use meaningful variable names
- Keep tests focused and simple

## ğŸ“ Support

### Getting Help

1. **Check documentation:**

   - [Test Scenarios](test_scenarios.md)
   - [Mock Server API](mock_server.py)

2. **Run validation:**

   ```bash
   python3 setup_tests.py --validate-only
   ```

3. **Check logs:**
   ```bash
   ./run_tests.sh --verbose
   ```

### Reporting Issues

When reporting test issues, include:

- Test environment details
- Error messages and stack traces
- Steps to reproduce
- Expected vs actual behavior
- Test configuration

## ğŸ“„ License

This testing suite is part of the RepoTorpedo project and follows the same license terms.

---

**Happy Testing! ğŸ§ªâœ¨**
